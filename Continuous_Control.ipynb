{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "# select this option to load version 1 (with a single agent) of the environment\n",
    "# env = UnityEnvironment(file_name='/data/Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64')\n",
    "\n",
    "# select this option to load version 2 (with 20 agents) of the environment\n",
    "env = UnityEnvironment(file_name='/data/Reacher_Linux_NoVis/Reacher.x86_64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import logging\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from ddpg_agent import Agent\n",
    "from workspace_utils import active_session\n",
    "import torch\n",
    "import time\n",
    "import random\n",
    "import utils\n",
    "from utils import Params\n",
    "from utils import set_logger\n",
    "from itertools import count\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpg(experiment_name, agents, scores_episode,  scores_window, start_episode, episodes_step, params, train_mode=True):\n",
    "    \n",
    "    success = False\n",
    "    max_t=1000\n",
    "    random.seed(2)\n",
    "    learn_exps = 0\n",
    "    completed = 0\n",
    "\n",
    "    scores = np.zeros(num_agents)\n",
    "\n",
    "    for i_episode in range(start_episode, start_episode+episodes_step):\n",
    "        env_info = env.reset(train_mode=train_mode)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "\n",
    "        for agent in agents:\n",
    "            agent.reset(completed)\n",
    "\n",
    "        scores = np.zeros(num_agents)\n",
    "        l_time = time.time()\n",
    "\n",
    "        for t in range(1, max_t):\n",
    "            \n",
    "            add_noise = True if completed < 90.0 else False         # don't add noise in once substatial experince\n",
    "\n",
    "            #actions = [agents[i].act(states[i]) for i in range(num_agents)]\n",
    "            actions = np.array([agents[i].act(states[i], add_noise) for i in range(num_agents)])\n",
    "            env_info = env.step(actions)[brain_name]        # send the action to the environment\n",
    "            next_states = env_info.vector_observations     # get the next state\n",
    "            rewards = env_info.rewards                     # get the reward\n",
    "            dones = env_info.local_done \n",
    "\n",
    "            #for i in range(num_agents):\n",
    "            #    learn_exps = agents[i].step(t, states[i], actions[i], rewards[i], next_states[i], dones[i], completed, np.mean(scores_window)) \n",
    "\n",
    "            agents[0].add_memory(states, actions, rewards, next_states, dones)\n",
    "            if t % params.time_steps == 0:\n",
    "                for i in range(num_agents):\n",
    "                    learn_exps = agents[i].sample_learning()\n",
    "\n",
    "            states = next_states\n",
    "            scores += rewards\n",
    "            if t % params.time_steps == 0:\n",
    "                print('\\rTimestep {}\\tScore: {:.2f}\\tmin/max: {:.2f}/{:.2f} ({:.2f})\\ttime: {:.2f}\\tlearn: {}.{}/{} - {}'\n",
    "                      .format(t, np.mean(scores), np.min(scores), np.max(scores), completed, time.time()-l_time, agent.batch_size, learn_exps, len(agent.memory), add_noise), end=\"\") \n",
    "            if np.any(dones):\n",
    "                break \n",
    "        score = np.mean(scores)\n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores_episode.append(score)\n",
    "\n",
    "        completed = score * 100.0 / params.target_score  \n",
    "\n",
    "        print('\\rEpisode {}\\tScore: {:.2f}\\tAverage Score: {:.2f}'.format(i_episode, score, np.mean(scores_window)), end=\"\\n\")\n",
    "        if np.mean(scores_window)>=params.target_score:\n",
    "            success = True\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "            break\n",
    "                \n",
    "    torch.save(agent.actor_local.state_dict(), 'checkpoint_actor4.pth')\n",
    "    torch.save(agent.critic_local.state_dict(), 'checkpoint_critic4.pth')\n",
    "    torch.save(scores_episode, 'checkpoint_scores_episode4.pth')\n",
    "    torch.save(scores_window, 'checkpoint_scores_window4.pth')\n",
    "            \n",
    "    return success, scores_episode\n",
    "\n",
    "##################################################################################################################################\n",
    "\n",
    "\n",
    "def plot(scores_episode):\n",
    "    # plot the scores.\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.plot(np.arange(len(scores_episode)), scores_episode)\n",
    "    plt.ylabel('Score')\n",
    "    plt.xlabel('Episode #')\n",
    "    plt.title(\"Ave mean scores\")\n",
    "    plt.show()\n",
    "\n",
    "def list_params(params, json_path):\n",
    "\n",
    "    logging.info(\"\\rUsing hyperparameters from {}\".format(json_path))\n",
    "    for keys,values in params.__dict__.items():\n",
    "        logging.info('\\r\\t {}\\t: {}'.format(keys, values))\n",
    "        \n",
    "\n",
    "def run_model(experiment_name, train_mode, reload=False):\n",
    "\n",
    "    if experiment_name == None:\n",
    "        experiment_name = input(\"enter experiment name (eg 20Agents):\")\n",
    "        if experiment_name == \"\":\n",
    "            experiment_name = \"20Agents\"\n",
    "            \n",
    "    if experiment_name == None:\n",
    "        train_mode = input(\"Train/Eval:\")\n",
    "        if train_mode == \"\":\n",
    "            train_mode = \"Train,Eval\"\n",
    "    \n",
    "    set_logger(experiment_name + \".log\")\n",
    "\n",
    "    print('Train Mode: ',train_mode)\n",
    "    print('Number of agents:', num_agents)\n",
    "\n",
    "    params = Params(\"data/params.json\")\n",
    "    list_params(params, \"data/params.json\")\n",
    "\n",
    "    n_episodes = params.train_episodes\n",
    "    episodes_step = 20\n",
    "\n",
    "    scores_episode = []\n",
    "    scores_window = deque(maxlen=100)\n",
    "    agents = [] \n",
    "\n",
    "    if reload:\n",
    "        for i in range(num_agents):\n",
    "            agent = Agent(state_size, action_size, random_seed=2, params=params)\n",
    "            agent.actor_local.load_state_dict(torch.load('checkpoint_actor2.pth'))\n",
    "            agent.critic_local.load_state_dict(torch.load('checkpoint_critic2.pth'))   \n",
    "            agents.append(agent)\n",
    "            scores_episode = torch.load('checkpoint_scores_episode2.pth',map_location=torch.device('cpu'))\n",
    "            scores_window = torch.load('checkpoint_scores_window2.pth',map_location=torch.device('cpu'))\n",
    "    else:\n",
    "        for i in range(num_agents):\n",
    "            agents.append(Agent(state_size, action_size, random_seed=2, params=params))    \n",
    "\n",
    "    ##################################################################################################################################\n",
    "\n",
    "    start_episode = 181\n",
    "    start_time = time.time()\n",
    "\n",
    "    #with active_session():\n",
    "\n",
    "    for i_episode in range(start_episode, n_episodes+1, episodes_step):\n",
    "        \n",
    "        if \"Train\" in train_mode:\n",
    "            # Train the agent\n",
    "            success, scores_episode = ddpg(experiment_name, agents, scores_episode,  scores_window, i_episode, episodes_step, params=params, train_mode=True)\n",
    "\n",
    "        if \"Eval\" in train_mode:\n",
    "            # Test 'Trained' Agent\n",
    "            success, scores_episode = ddpg(experiment_name, agents, scores_episode,  scores_window, i_episode, episodes_step, params=params, train_mode=False)\n",
    "\n",
    "        print('\\rEpisode {}\\ Score: {:.2f} in {:.2f}'.format(len(scores_episode), np.mean(scores_window), time.time()-start_time), end=\"\\n\")\n",
    "\n",
    "        if success:\n",
    "            break\n",
    "    \n",
    "    return scores_episode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using hyperparameters from data/20Agents/params.json\n",
      "\t experiment_name\t: 20Agents\n",
      "\t model_type\t: DDPG\n",
      "\t use_model\t: False\n",
      "\t num_agents\t: 20\n",
      "\t buffer_size\t: 1000000.0\n",
      "\t batch_size\t: 64\n",
      "\t gamma\t: 0.99\n",
      "\t time_steps\t: 20\n",
      "\t update_rate\t: 10\n",
      "\t target_tau\t: 0.001\n",
      "\t lr_actor\t: 0.0001\n",
      "\t lr_critic\t: 0.0003\n",
      "\t weight_decay\t: 0.0001\n",
      "\t dropout\t: 0.2\n",
      "\t mean_windowsize\t: 100\n",
      "\t t_max\t: 500\n",
      "\t target_score\t: 30.0\n",
      "\t train_episodes\t: 1000\n",
      "\t test_episodes\t: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mode:  Train\n",
      "Number of agents: 20\n",
      "load model: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 1\tAverage Score: 0.02\tElapse time: 17.77\n",
      "Episode 2\tAverage Score: 0.02\tElapse time: 31.90\n",
      "Episode 3\tAverage Score: 0.02\tElapse time: 32.16\n",
      "Episode 4\tAverage Score: 0.02\tElapse time: 46.35\n",
      "Episode 5\tAverage Score: 0.04\tElapse time: 60.45\n",
      "Episode 6\tAverage Score: 0.05\tElapse time: 60.75\n",
      "Episode 7\tAverage Score: 0.09\tElapse time: 76.05\n",
      "Episode 8\tAverage Score: 0.17\tElapse time: 92.66\n",
      "Episode 9\tAverage Score: 0.23\tElapse time: 93.01\n",
      "Episode 10\tAverage Score: 0.30\tElapse time: 110.91\n",
      "Episode 11\tAverage Score: 0.40\tElapse time: 128.31\n",
      "Episode 12\tAverage Score: 0.48\tElapse time: 128.65\n",
      "Episode 13\tAverage Score: 0.58\tElapse time: 145.64\n",
      "Episode 14\tAverage Score: 0.69\tElapse time: 162.09\n",
      "Episode 15\tAverage Score: 0.78\tElapse time: 162.40\n",
      "Episode 16\tAverage Score: 0.89\tElapse time: 178.71\n",
      "Episode 17\tAverage Score: 1.00\tElapse time: 193.77\n",
      "Episode 18\tAverage Score: 1.10\tElapse time: 194.06\n",
      "Episode 19\tAverage Score: 1.21\tElapse time: 208.51\n",
      "Episode 20\tAverage Score: 1.32\tElapse time: 223.69\n",
      "Episode 21\tAverage Score: 1.43\tElapse time: 223.99\n",
      "Episode 22\tAverage Score: 1.54\tElapse time: 238.68\n",
      "Episode 23\tAverage Score: 1.66\tElapse time: 253.49\n",
      "Episode 24\tAverage Score: 1.77\tElapse time: 253.79\n",
      "Episode 25\tAverage Score: 1.88\tElapse time: 268.69\n",
      "Episode 26\tAverage Score: 1.99\tElapse time: 283.65\n",
      "Episode 27\tAverage Score: 2.09\tElapse time: 283.94\n",
      "Episode 28\tAverage Score: 2.19\tElapse time: 298.69\n",
      "Episode 29\tAverage Score: 2.29\tElapse time: 313.79\n",
      "Episode 30\tAverage Score: 2.39\tElapse time: 314.08\n",
      "Episode 31\tAverage Score: 2.48\tElapse time: 328.70\n",
      "Episode 32\tAverage Score: 2.58\tElapse time: 343.24\n",
      "Episode 33\tAverage Score: 2.67\tElapse time: 343.53\n",
      "Episode 34\tAverage Score: 2.77\tElapse time: 358.04\n",
      "Episode 35\tAverage Score: 2.87\tElapse time: 373.04\n",
      "Episode 36\tAverage Score: 2.96\tElapse time: 373.31\n",
      "Episode 37\tAverage Score: 3.05\tElapse time: 387.83\n",
      "Episode 38\tAverage Score: 3.14\tElapse time: 402.27\n",
      "Episode 39\tAverage Score: 3.22\tElapse time: 402.55\n",
      "Episode 40\tAverage Score: 3.31\tElapse time: 417.29\n",
      "Episode 41\tAverage Score: 3.40\tElapse time: 433.24\n",
      "Episode 42\tAverage Score: 3.48\tElapse time: 433.58\n",
      "Episode 43\tAverage Score: 3.56\tElapse time: 449.47\n",
      "Episode 44\tAverage Score: 3.65\tElapse time: 464.07\n",
      "Episode 45\tAverage Score: 3.73\tElapse time: 464.38\n",
      "Episode 46\tAverage Score: 3.81\tElapse time: 478.90\n",
      "Episode 47\tAverage Score: 3.89\tElapse time: 493.48\n",
      "Episode 48\tAverage Score: 3.97\tElapse time: 493.77\n",
      "Episode 49\tAverage Score: 4.05\tElapse time: 508.76\n",
      "Episode 50\tAverage Score: 4.14\tElapse time: 523.28\n",
      "Episode 51\tAverage Score: 4.22\tElapse time: 523.57\n",
      "Episode 52\tAverage Score: 4.31\tElapse time: 538.21\n",
      "Episode 53\tAverage Score: 4.39\tElapse time: 552.83\n",
      "Episode 54\tAverage Score: 4.48\tElapse time: 553.12\n",
      "Episode 55\tAverage Score: 4.56\tElapse time: 568.43\n",
      "Episode 56\tAverage Score: 4.65\tElapse time: 583.04\n",
      "Episode 57\tAverage Score: 4.74\tElapse time: 583.33\n",
      "Episode 58\tAverage Score: 4.83\tElapse time: 597.91\n",
      "Episode 59\tAverage Score: 4.92\tElapse time: 612.50\n",
      "Episode 60\tAverage Score: 5.01\tElapse time: 612.79\n",
      "Episode 61\tAverage Score: 5.10\tElapse time: 627.54\n",
      "Episode 62\tAverage Score: 5.20\tElapse time: 642.51\n",
      "Episode 63\tAverage Score: 5.29\tElapse time: 642.81\n",
      "Episode 64\tAverage Score: 5.38\tElapse time: 657.38\n",
      "Episode 65\tAverage Score: 5.47\tElapse time: 672.16\n",
      "Episode 66\tAverage Score: 5.56\tElapse time: 672.45\n",
      "Episode 67\tAverage Score: 5.65\tElapse time: 687.53\n",
      "Episode 68\tAverage Score: 5.75\tElapse time: 702.82\n",
      "Episode 69\tAverage Score: 5.84\tElapse time: 703.12\n",
      "Episode 70\tAverage Score: 5.93\tElapse time: 717.69\n",
      "Episode 71\tAverage Score: 6.03\tElapse time: 732.35\n",
      "Episode 72\tAverage Score: 6.12\tElapse time: 732.65\n",
      "Episode 73\tAverage Score: 6.22\tElapse time: 747.22\n",
      "Episode 74\tAverage Score: 6.31\tElapse time: 762.19\n",
      "Episode 75\tAverage Score: 6.40\tElapse time: 762.53\n",
      "Episode 76\tAverage Score: 6.50\tElapse time: 777.18\n",
      "Episode 77\tAverage Score: 6.60\tElapse time: 791.73\n",
      "Episode 78\tAverage Score: 6.69\tElapse time: 792.03\n",
      "Episode 79\tAverage Score: 6.79\tElapse time: 806.77\n",
      "Episode 80\tAverage Score: 6.89\tElapse time: 821.63\n",
      "Episode 81\tAverage Score: 6.98\tElapse time: 821.94\n",
      "Episode 82\tAverage Score: 7.08\tElapse time: 837.61\n",
      "Episode 83\tAverage Score: 7.18\tElapse time: 852.74\n",
      "Episode 84\tAverage Score: 7.27\tElapse time: 853.03\n",
      "Episode 85\tAverage Score: 7.37\tElapse time: 868.00\n",
      "Episode 86\tAverage Score: 7.47\tElapse time: 882.99\n",
      "Episode 87\tAverage Score: 7.56\tElapse time: 883.27\n",
      "Episode 88\tAverage Score: 7.66\tElapse time: 899.27\n",
      "Episode 89\tAverage Score: 7.76\tElapse time: 914.31\n",
      "Episode 90\tAverage Score: 7.85\tElapse time: 914.60\n",
      "Episode 91\tAverage Score: 7.95\tElapse time: 929.64\n",
      "Episode 92\tAverage Score: 8.05\tElapse time: 944.59\n",
      "Episode 93\tAverage Score: 8.14\tElapse time: 944.88\n",
      "Episode 94\tAverage Score: 8.24\tElapse time: 960.28\n",
      "Episode 95\tAverage Score: 8.34\tElapse time: 975.30\n",
      "Episode 96\tAverage Score: 8.43\tElapse time: 975.60\n",
      "Episode 97\tAverage Score: 8.53\tElapse time: 990.58\n",
      "Episode 98\tAverage Score: 8.62\tElapse time: 1005.52\n",
      "Episode 99\tAverage Score: 8.72\tElapse time: 1005.81\n",
      "Episode 100\tAverage Score: 8.81\tElapse time: 1021.01\n",
      "Episode 101\tAverage Score: 9.00\tElapse time: 1036.96\n",
      "Episode 102\tAverage Score: 9.19\tElapse time: 1037.33\n",
      "Episode 103\tAverage Score: 9.38\tElapse time: 1052.40\n",
      "Episode 104\tAverage Score: 9.57\tElapse time: 1067.35\n",
      "Episode 105\tAverage Score: 9.77\tElapse time: 1067.65\n",
      "Episode 106\tAverage Score: 9.96\tElapse time: 1082.59\n",
      "Episode 107\tAverage Score: 10.16\tElapse time: 1098.12\n",
      "Episode 108\tAverage Score: 10.35\tElapse time: 1098.41\n",
      "Episode 109\tAverage Score: 10.55\tElapse time: 1113.39\n",
      "Episode 110\tAverage Score: 10.74\tElapse time: 1128.36\n",
      "Episode 111\tAverage Score: 10.93\tElapse time: 1128.65\n",
      "Episode 112\tAverage Score: 11.13\tElapse time: 1143.82\n",
      "Episode 113\tAverage Score: 11.33\tElapse time: 1159.45\n",
      "Episode 114\tAverage Score: 11.52\tElapse time: 1159.74\n",
      "Episode 115\tAverage Score: 11.71\tElapse time: 1174.75\n",
      "Episode 116\tAverage Score: 11.90\tElapse time: 1189.80\n",
      "Episode 117\tAverage Score: 12.09\tElapse time: 1190.08\n",
      "Episode 118\tAverage Score: 12.29\tElapse time: 1205.22\n",
      "Episode 119\tAverage Score: 12.48\tElapse time: 1220.42\n",
      "Episode 120\tAverage Score: 12.67\tElapse time: 1220.73\n",
      "Episode 121\tAverage Score: 12.86\tElapse time: 1236.22\n",
      "Episode 122\tAverage Score: 13.05\tElapse time: 1251.28\n",
      "Episode 123\tAverage Score: 13.24\tElapse time: 1251.56\n",
      "Episode 124\tAverage Score: 13.43\tElapse time: 1266.75\n",
      "Episode 125\tAverage Score: 13.62\tElapse time: 1281.69\n",
      "Episode 126\tAverage Score: 13.80\tElapse time: 1281.99\n",
      "Episode 127\tAverage Score: 13.99\tElapse time: 1297.75\n",
      "Episode 128\tAverage Score: 14.18\tElapse time: 1312.70\n",
      "Episode 129\tAverage Score: 14.37\tElapse time: 1313.00\n",
      "Episode 130\tAverage Score: 14.56\tElapse time: 1328.13\n",
      "Episode 131\tAverage Score: 14.75\tElapse time: 1343.11\n",
      "Episode 132\tAverage Score: 14.94\tElapse time: 1343.39\n",
      "Episode 133\tAverage Score: 15.13\tElapse time: 1358.81\n",
      "Episode 134\tAverage Score: 15.32\tElapse time: 1373.86\n",
      "Episode 135\tAverage Score: 15.51\tElapse time: 1374.15\n",
      "Episode 136\tAverage Score: 15.70\tElapse time: 1389.23\n",
      "Episode 137\tAverage Score: 15.89\tElapse time: 1404.16\n",
      "Episode 138\tAverage Score: 16.08\tElapse time: 1404.45\n",
      "Episode 139\tAverage Score: 16.27\tElapse time: 1419.89\n",
      "Episode 140\tAverage Score: 16.47\tElapse time: 1434.93\n",
      "Episode 141\tAverage Score: 16.66\tElapse time: 1435.25\n",
      "Episode 142\tAverage Score: 16.85\tElapse time: 1450.28\n",
      "Episode 143\tAverage Score: 17.05\tElapse time: 1465.57\n",
      "Episode 144\tAverage Score: 17.24\tElapse time: 1465.86\n",
      "Episode 145\tAverage Score: 17.44\tElapse time: 1480.93\n",
      "Episode 146\tAverage Score: 17.64\tElapse time: 1496.47\n",
      "Episode 147\tAverage Score: 17.83\tElapse time: 1496.75\n",
      "Episode 148\tAverage Score: 18.03\tElapse time: 1512.06\n",
      "Episode 149\tAverage Score: 18.23\tElapse time: 1527.35\n",
      "Episode 150\tAverage Score: 18.42\tElapse time: 1527.64\n",
      "Episode 151\tAverage Score: 18.62\tElapse time: 1542.72\n",
      "Episode 152\tAverage Score: 18.82\tElapse time: 1558.32\n",
      "Episode 153\tAverage Score: 19.01\tElapse time: 1558.61\n",
      "Episode 154\tAverage Score: 19.21\tElapse time: 1573.54\n",
      "Episode 155\tAverage Score: 19.40\tElapse time: 1588.55\n",
      "Episode 156\tAverage Score: 19.60\tElapse time: 1588.84\n",
      "Episode 157\tAverage Score: 19.79\tElapse time: 1603.77\n",
      "Episode 158\tAverage Score: 19.99\tElapse time: 1619.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 159\tAverage Score: 20.18\tElapse time: 1619.84\n",
      "Episode 160\tAverage Score: 20.38\tElapse time: 1635.02\n",
      "Episode 161\tAverage Score: 20.57\tElapse time: 1650.24\n",
      "Episode 162\tAverage Score: 20.77\tElapse time: 1650.53\n",
      "Episode 163\tAverage Score: 20.96\tElapse time: 1665.86\n",
      "Episode 164\tAverage Score: 21.16\tElapse time: 1681.54\n",
      "Episode 165\tAverage Score: 21.36\tElapse time: 1681.86\n",
      "Episode 166\tAverage Score: 21.55\tElapse time: 1697.21\n",
      "Episode 167\tAverage Score: 21.75\tElapse time: 1712.42\n",
      "Episode 168\tAverage Score: 21.95\tElapse time: 1712.73\n",
      "Episode 169\tAverage Score: 22.14\tElapse time: 1727.82\n",
      "Episode 170\tAverage Score: 22.34\tElapse time: 1742.96\n",
      "Episode 171\tAverage Score: 22.53\tElapse time: 1743.25\n",
      "Episode 172\tAverage Score: 22.73\tElapse time: 1759.04\n",
      "Episode 173\tAverage Score: 22.93\tElapse time: 1774.06\n",
      "Episode 174\tAverage Score: 23.12\tElapse time: 1774.35\n",
      "Episode 175\tAverage Score: 23.32\tElapse time: 1789.41\n",
      "Episode 176\tAverage Score: 23.52\tElapse time: 1804.59\n",
      "Episode 177\tAverage Score: 23.71\tElapse time: 1804.88\n",
      "Episode 178\tAverage Score: 23.91\tElapse time: 1820.40\n",
      "Episode 179\tAverage Score: 24.11\tElapse time: 1835.42\n",
      "Episode 180\tAverage Score: 24.30\tElapse time: 1835.71\n",
      "Episode 181\tAverage Score: 24.50\tElapse time: 1850.88\n",
      "Episode 182\tAverage Score: 24.69\tElapse time: 1865.98\n",
      "Episode 183\tAverage Score: 24.88\tElapse time: 1866.27\n",
      "Episode 184\tAverage Score: 25.08\tElapse time: 1881.90\n",
      "Episode 185\tAverage Score: 25.27\tElapse time: 1896.90\n",
      "Episode 186\tAverage Score: 25.47\tElapse time: 1897.20\n",
      "Episode 187\tAverage Score: 25.66\tElapse time: 1912.53\n",
      "Episode 188\tAverage Score: 25.86\tElapse time: 1928.23\n",
      "Episode 189\tAverage Score: 26.05\tElapse time: 1928.52\n",
      "Episode 190\tAverage Score: 26.25\tElapse time: 1944.24\n",
      "Episode 191\tAverage Score: 26.44\tElapse time: 1959.81\n",
      "Episode 192\tAverage Score: 26.64\tElapse time: 1960.11\n",
      "Episode 193\tAverage Score: 26.83\tElapse time: 1975.53\n",
      "Episode 194\tAverage Score: 27.03\tElapse time: 1991.02\n",
      "Episode 195\tAverage Score: 27.23\tElapse time: 1991.31\n",
      "Episode 196\tAverage Score: 27.42\tElapse time: 2006.62\n",
      "Episode 197\tAverage Score: 27.62\tElapse time: 2022.48\n",
      "Episode 198\tAverage Score: 27.82\tElapse time: 2022.79\n",
      "Episode 199\tAverage Score: 28.01\tElapse time: 2038.10\n",
      "Episode 200\tAverage Score: 28.21\tElapse time: 2053.18\n",
      "Episode 201\tAverage Score: 28.40\tElapse time: 2053.49\n",
      "Episode 202\tAverage Score: 28.60\tElapse time: 2068.67\n",
      "Episode 203\tAverage Score: 28.79\tElapse time: 2086.07\n",
      "Episode 204\tAverage Score: 28.98\tElapse time: 2086.37\n",
      "Episode 205\tAverage Score: 29.17\tElapse time: 2101.74\n",
      "Episode 206\tAverage Score: 29.36\tElapse time: 2116.97\n",
      "Episode 207\tAverage Score: 29.55\tElapse time: 2117.27\n",
      "Episode 208\tAverage Score: 29.74\tElapse time: 2132.63\n",
      "Episode 209\tAverage Score: 29.94\tElapse time: 2148.28\n",
      "Episode 210\tAverage Score: 30.12\tElapse time: 2148.57\n",
      "INFO:root:\n",
      "Environment solved in 210 episodes!\tAverage Score: 30.12\tElapse time: 2148.57\n"
     ]
    }
   ],
   "source": [
    "with active_session():\n",
    "    scores = run_model(\"20Agents\",\"Train\", reload=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
